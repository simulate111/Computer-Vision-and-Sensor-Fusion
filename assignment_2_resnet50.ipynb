{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Computer-Vision-and-Sensor-Fusion/blob/main/assignment_2_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAQr-XfCAziO"
      },
      "source": [
        "### Add libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sz2NL_1RAziS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet import ResNet50\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8t9G4XaAziW"
      },
      "source": [
        "### Path system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nud0wxdmAziX",
        "outputId": "1a6c747f-b0c6-4b9b-8c0d-6710c14e789d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DIR] The directory of the current dataset is /Datasets/weather_dataset\n"
          ]
        }
      ],
      "source": [
        "# you need the current working directory NB: works both windows and linux\n",
        "current_working_directory = os.getcwd()\n",
        "current_working_directory = os.path.dirname(current_working_directory)\n",
        "\n",
        "# get the directory where I want to download the dataset\n",
        "path_of_download = os.path.join(*['..', current_working_directory, 'Datasets', 'weather_dataset'])\n",
        "print(f\"[DIR] The directory of the current dataset is {path_of_download}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa2gHfK5AziY"
      },
      "source": [
        "### function for data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eIhPiXr3AziY"
      },
      "outputs": [],
      "source": [
        "# here let s do some functions that we can re-use also for other assignment\n",
        "def load_the_data_and_the_labels(data_set_path: str, target_size: tuple or None = None):\n",
        "    try:\n",
        "        dataset, labels, name_of_the_labels = list(), list(), list()\n",
        "        # let s loop here and we try to discover how many class we have\n",
        "        for class_number, class_name in enumerate(os.listdir(data_set_path)):\n",
        "            full_path_the_data = os.path.join(data_set_path, class_name)\n",
        "            print(f\"[WALK] I am walking into {full_path_the_data}\")\n",
        "\n",
        "            # add the list to nam _list\n",
        "            name_of_the_labels.append(class_name)\n",
        "\n",
        "            for single_image in os.listdir(f\"{full_path_the_data}\"):\n",
        "                full_path_to_image = os.path.join(*[full_path_the_data, single_image])\n",
        "\n",
        "                # add the class number\n",
        "                labels.append(class_number)\n",
        "\n",
        "                if target_size is None:\n",
        "                    # let s load the image\n",
        "                    image = tf.keras.utils.load_img(full_path_to_image)\n",
        "                else:\n",
        "                    image = tf.keras.utils.load_img(full_path_to_image, target_size=target_size)\n",
        "\n",
        "                # transform PIL object in image\n",
        "                image = tf.keras.utils.img_to_array(image)\n",
        "\n",
        "                # add the image to the ds list\n",
        "                dataset.append(image)\n",
        "\n",
        "        return np.array(dataset, dtype='uint8'), np.array(labels, dtype='int'), name_of_the_labels\n",
        "    except Exception as ex:\n",
        "        print(f\"[EXCEPTION] load the data and the labels throws exceptions {ex}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlJhk3N_Azia"
      },
      "source": [
        "### OHE function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8uTXiW-qAzic"
      },
      "outputs": [],
      "source": [
        "# here we have to one hot encode the labes\n",
        "def make_the_one_hot_encoding(labels_to_transform):\n",
        "    try:\n",
        "        enc = OneHotEncoder(handle_unknown='ignore')\n",
        "        # this is a trick to figure the array as 2d array instead of list\n",
        "        temp = np.reshape(labels_to_transform, (-1, 1))\n",
        "        labels_to_transform = enc.fit_transform(temp).toarray()\n",
        "        print(f'[ONE HOT ENCODING] Labels are one-hot-encoded: {(labels_to_transform.sum(axis=1) - np.ones(labels_to_transform.shape[0])).sum() == 0}')\n",
        "        return labels_to_transform\n",
        "    except Exception as ex:\n",
        "        print(f\"[EXCEPTION] Make the one hot encoding throws exception {ex}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYoAaWjcAzid"
      },
      "source": [
        "### load the data and labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "id": "istrWpPgbQO8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://seafile.utu.fi/f/88c08f841e0348e1a412/?dl=1\"\n",
        "zip_path = \"/content/weather_dataset.zip\"\n",
        "urllib.request.urlretrieve(url, zip_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaM3z0YHbp0a",
        "outputId": "e129156a-a950-4f2a-fe40-3ed7a2d3b152"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/weather_dataset.zip', <http.client.HTTPMessage at 0x7a0989126050>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_path = \"/content/weather_dataset\"\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "ZeozQhC7bXD0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, labels, class_names = load_the_data_and_the_labels(\"/content/weather_dataset/weather_dataset\", target_size=(224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX4Ttpg_bAJ8",
        "outputId": "672083b5-2916-4ae0-8230-a4397571dbfd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WALK] I am walking into /content/weather_dataset/weather_dataset/Sunrise\n",
            "[WALK] I am walking into /content/weather_dataset/weather_dataset/Rain\n",
            "[WALK] I am walking into /content/weather_dataset/weather_dataset/Shine\n",
            "[WALK] I am walking into /content/weather_dataset/weather_dataset/Cloudy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaPeBtYCAzie"
      },
      "source": [
        "### normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8Hsxpc2EAzif"
      },
      "outputs": [],
      "source": [
        "# Normalize images\n",
        "dataset = dataset / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_labels = make_the_one_hot_encoding(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhurFIvf381n",
        "outputId": "5839a4e6-5115-4c19-ed5e-04df1bf2f2d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ONE HOT ENCODING] Labels are one-hot-encoded: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAS0xXyOAzig"
      },
      "source": [
        "### split the dataset in train and test set (ratio 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hsLGkzzkAzig"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataset, encoded_labels, test_size=0.3, stratify=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mJZkxdKAzig"
      },
      "source": [
        "### create the CNN and set all parameters to trainable\n",
        "a.\tInput layer\n",
        "b.\tAs base model use VGG19:\n",
        "    i.\tWeights: imagenet\n",
        "    ii.\tInclude_top: False\n",
        "    iii.\tInput_shape the target shape described in point 1.\n",
        "c.\tAdd a flatten layer\n",
        "d.\tAdd a Dense layer with 512 units and a dropout layer with 0.1 unit.\n",
        "e.\tAdd a Dense layer with 256 units and a dropout layer with 0.1 unit.\n",
        "f.\tAdd the final classifier with the correct number of units and the suitable activation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ycvLwmPVAzig"
      },
      "outputs": [],
      "source": [
        "def cnn_ResNet50(input_shape=(224, 224, 3), num_classes=4):\n",
        "    #a\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    #b\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "    base_model.trainable = True\n",
        "    #c\n",
        "    flatten_layer = Flatten()(base_model.output)\n",
        "    #d\n",
        "    dense = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
        "    dropout = Dropout(0.1)(dense)\n",
        "    #e\n",
        "    dense2 = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(dropout)\n",
        "    dropout2 = Dropout(0.1)(dense2)\n",
        "    #f\n",
        "    output_layer = Dense(num_classes, activation='softmax')(dropout2)\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn_ResNet50()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "NXuF3v882S_a",
        "outputId": "e74a78cf-013d-459e-8a39-6b7b83e3e9ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'l2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f25f10210248>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_ResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-2a84bc6e7c0d>\u001b[0m in \u001b[0;36mcnn_ResNet50\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mflatten_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'l2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdj0IV7oAzih"
      },
      "source": [
        "### compile the model with adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ-cvQWsAzih"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olm0gBGwAzih"
      },
      "source": [
        "### Fit the model with batch size 32 and 15 epochs (This take 15 - 20 minutes with the CPU)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "Deu2J6MHT3LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=15, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "QRQlhczogDca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFKbkhyFAzih"
      },
      "source": [
        "### Evaluate  the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI3ucEjLAzih"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvlS0DyiAzii"
      },
      "source": [
        "#### Make and show predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jthngnE8Azii"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "def plot_predictions(images, true_labels, predicted_labels, class_names, num_images=8):\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        true_label = class_names[true_labels[i]]\n",
        "        predicted_label = class_names[predicted_labels[i]]\n",
        "        plt.title(f\"True: {true_label}\\nPred: {predicted_label}\")\n",
        "plot_predictions(X_test, true_classes, predicted_classes, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcYypGbAAzii"
      },
      "source": [
        "### make confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc0nAirIAzii"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=class_names)\n",
        "disp.plot(cmap=plt.cm.Blues)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f_pJSVrAzii"
      },
      "source": [
        "### Load again the cnn but this time set the parameters to NOT TRAINABLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja-xZS7JAzii"
      },
      "outputs": [],
      "source": [
        "def cnn_ResNet50_non_trainable(input_shape=(224, 224, 3), num_classes=4):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "    base_model.trainable = False\n",
        "    flatten_layer = Flatten()(base_model.output)\n",
        "    dense = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
        "    dropout = Dropout(0.1)(dense)\n",
        "    dense2 = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(dropout)\n",
        "    dropout2 = Dropout(0.1)(dense2)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(dropout2)\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5orAaxQNAzii"
      },
      "source": [
        "### Fit the model with batch size 32 and 15 epochs (This is fsaster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaNRNE7kAzii"
      },
      "outputs": [],
      "source": [
        "model2 = cnn_ResNet50_non_trainable()\n",
        "model2.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=15, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R9F8Iq9Azii"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWewSL9RAzij"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model2.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22tmstVcAzij"
      },
      "source": [
        "### Make and show some predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLlDeAlWAzij"
      },
      "outputs": [],
      "source": [
        "y_pred = model2.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "num_samples = 5\n",
        "random_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    plt.subplot(1, num_samples, i + 1)\n",
        "    plt.imshow(X_test[idx])\n",
        "    true_label = y_true_classes[idx]\n",
        "    pred_label = y_pred_classes[idx]\n",
        "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model2.predict(X_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "def plot_predictions(images, true_labels, predicted_labels, class_names, num_images=8):\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        true_label = class_names[true_labels[i]]\n",
        "        predicted_label = class_names[predicted_labels[i]]\n",
        "        plt.title(f\"True: {true_label}\\nPred: {predicted_label}\")\n",
        "plot_predictions(X_test, true_classes, predicted_classes, class_names)"
      ],
      "metadata": {
        "id": "X_5B6mqg--d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=class_names)\n",
        "disp.plot(cmap=plt.cm.Blues)"
      ],
      "metadata": {
        "id": "zJxLMfECSgva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.model_selection import KFold\n",
        "#K-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "    model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10)\n",
        "'''"
      ],
      "metadata": {
        "id": "BKoDS2clThwq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}